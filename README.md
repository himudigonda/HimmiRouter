# HimmiRouter â€” Enterprise AI Workbench

> An OpenRouter-grade LLM Inference Gateway with a premium AI Workbench UI. Built with FastAPI, LangGraph, MCP, and React.

---

## âœ¨ What Is This?

HimmiRouter is a **full-stack AI platform** that routes LLM requests through a secure, observable, and credit-aware gateway. It ships with:

- ğŸ§  **AI Playground** â€” ChatGPT-style streaming chat interface
- ğŸ“¦ **Model Library** â€” Browse all available models and pricing
- ğŸ”‘ **API Key Management** â€” Create and manage scoped keys
- ğŸ’³ **Credit System** â€” Atomic per-request billing with real-time balance
- ğŸ“¡ **MCP Server** â€” Expose the gateway to external agents (Claude, Cursor, etc.)
- ğŸ”­ **Observability** â€” Full OpenTelemetry traces in Jaeger

---

## ğŸ—ï¸ Architecture

```mermaid
graph TD
    subgraph Frontend
        Dashboard["Dashboard Frontend<br/>(React + Vite + Shadcn UI)<br/>localhost:5173"]
    end

    subgraph Backend
        Control["Control Plane (FastAPI)<br/>port 8000<br/>â€¢ Auth (JWT)<br/>â€¢ API Key Mgmt<br/>â€¢ User Credits<br/>â€¢ Model Catalog"]
        Gateway["Inference Gateway (FastAPI + LangGraph)<br/>port 4000<br/>â€¢ Auth Node<br/>â€¢ Route Node<br/>â€¢ LLM Node<br/>â€¢ Billing Node<br/>â€¢ SSE Streaming"]
    end

    subgraph Database
        DB["PostgreSQL (port 5432)<br/>Users â€¢ ApiKeys â€¢ Models â€¢ Providers"]
    end

    Dashboard --> Control
    Dashboard --> Gateway
    Control --> DB
    Gateway --> DB
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
| :--- | :--- |
| Backend Language | Python 3.12 via `uv` |
| API Framework | FastAPI |
| LLM Orchestration | LangGraph (stateful graph) |
| LLM Proxy | LiteLLM |
| Database ORM | SQLModel + Alembic |
| Database | PostgreSQL 15 |
| Auth | JWT (python-jose) + Argon2 hashing |
| Observability | OpenTelemetry + Jaeger |
| Agent Protocol | Model Context Protocol (MCP) |
| Frontend | React 18 + Vite + TypeScript |
| UI Components | Shadcn UI (Radix Primitives) |
| Animations | Framer Motion |
| Styling | Tailwind CSS |
| Package Manager | Bun (frontend), uv (backend) |
| Task Runner | Just |

---

## âœ… Prerequisites

Install these before anything else:

| Tool | Install |
| :--- | :--- |
| `uv` | `curl -LsSf https://astral.sh/uv/install.sh \| sh` |
| `just` | `brew install just` |
| `bun` | `curl -fsSL https://bun.sh/install \| bash` |
| `docker` | [Docker Desktop](https://www.docker.com/products/docker-desktop/) |

---

## ğŸš€ Setup From Scratch

### Step 1 â€” Clone & Configure

```bash
git clone <your-repo-url> HimmiRouter
cd HimmiRouter

# Copy environment config
cp .env.example .env
```

Edit `.env` with your values (defaults work for local dev):

```env
DATABASE_URL=postgresql+asyncpg://user:password@localhost:5432/openrouter
JWT_SECRET=super-secret-key-change-this-in-prod
API_KEY_SALT=optional-salt-for-hashing
REDIS_URL=redis://localhost:6379/0
```

### Step 2 â€” Start Infrastructure

```bash
# Start PostgreSQL, Redis, and Jaeger
docker compose -f docker-compose.dev.yml up -d

# Verify containers are running
docker compose -f docker-compose.dev.yml ps
```

### Step 3 â€” Install Python Dependencies

```bash
uv sync
```

### Step 4 â€” Run Database Migrations & Seed Data

```bash
# Apply all schema migrations
just migrate

# Seed models, providers, and pricing data
just seed
```

### Step 5 â€” Install & Build Frontend

```bash
# Generates OpenAPI clients + installs npm deps
just install-frontend
```

> **Note:** This runs `openapi-typescript-codegen` to generate typesafe API clients from the live backend specs. The Control Plane must be reachable for this step.

---

## â–¶ï¸ Running the Stack

Open **3 separate terminals** and run one command in each:

```bash
# Terminal 1 â€” Control Plane (Auth, Keys, Models)
just run-control
# â†’ http://localhost:8000
# â†’ Swagger UI: http://localhost:8000/docs

# Terminal 2 â€” Inference Gateway (LLM routing, billing, streaming)
just run-gateway
# â†’ http://localhost:4000
# â†’ Simulator Mode is ON by default (no real API keys needed)

# Terminal 3 â€” Dashboard Frontend
just run-frontend
# â†’ http://localhost:5173
```

---

## ğŸ§ª Simulator Mode

The Inference Gateway runs in **Simulator Mode** by default (`HIMMI_SIMULATOR=true` in the Justfile). This means:

- âœ… No real OpenAI/Anthropic/Google API keys needed
- âœ… Responses stream in real-time with word-by-word animation
- âœ… Credit deduction still works end-to-end
- âœ… Full auth, routing, and billing pipeline executes

To use **real models**, set `HIMMI_SIMULATOR=false` in the Justfile and add your provider API keys to `.env`:

```env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AIza...
```

---

## ğŸ–¥ï¸ Using the AI Workbench

1. **Open** `http://localhost:5173`
2. **Register** a new account (email + password)
3. **Dashboard** â†’ Generate an API Key (give it a name like "Playground Key")
4. **Playground** â†’ Paste your key into the API Key field
5. **Select a model** from the dropdown and start chatting
6. **Model Library** â†’ Browse all available models and their pricing

---

## ğŸ”‘ API Reference

### Control Plane (`localhost:8000`)

| Method | Endpoint | Description |
| :--- | :--- | :--- |
| `POST` | `/auth/register` | Register a new user |
| `POST` | `/auth/login` | Login, get JWT token |
| `POST` | `/api-keys/create` | Create a new API key |
| `GET` | `/api-keys` | List your API keys |
| `GET` | `/models` | List all available models |
| `GET` | `/users/{user_id}` | Get user status & credits |

Full interactive docs: **[http://localhost:8000/docs](http://localhost:8000/docs)**

### Inference Gateway (`localhost:4000`)

| Method | Endpoint | Description |
| :--- | :--- | :--- |
| `POST` | `/v1/chat/completions` | OpenAI-compatible chat endpoint |
| `GET` | `/health` | Health check |
| `GET` | `/mcp/sse` | MCP agent connection endpoint |

---

## ğŸ¤– MCP Integration

Connect any MCP-compatible agent (Claude Desktop, Cursor, etc.) to HimmiRouter:

**Endpoint:** `http://localhost:4000/mcp/sse`

**Available Tools:**
- `chat_with_model(api_key, model, prompt)` â€” Route a prompt through the full billing-aware pipeline

**Example Claude Desktop config (`claude_desktop_config.json`):**
```json
{
  "mcpServers": {
    "himmirouter": {
      "url": "http://localhost:4000/mcp/sse"
    }
  }
}
```

---

## ğŸ”­ Observability

Every LLM request generates full distributed traces:

- **Jaeger UI:** `http://localhost:16686`
- Traces include: `auth` â†’ `route` â†’ `llm` â†’ `billing` nodes
- See token counts, latency, and errors per node

---

## ğŸ§° Justfile Commands

```bash
just setup           # Full first-time setup (infra + migrate + seed)
just migrate         # Run Alembic migrations
just seed            # Seed model/provider data
just run-control     # Start Control Plane (port 8000)
just run-gateway     # Start Inference Gateway (port 4000, Simulator ON)
just run-frontend    # Start Dashboard (port 5173)
just run-all         # Start all 3 services in background
just kill-all        # Stop all running background processes
just destroy         # Stop processes, down docker volumes, clean generated code
just install-frontend # Regenerate API clients + install frontend deps
just generate-spec   # Regenerate OpenAPI specs from live backend
just lint            # Run ruff linter with auto-fix
just test            # Run pytest
```

---

## ğŸ“ Project Structure

```mermaid
graph TD
    Root([HimmiRouter/]) --> Apps[/apps/dashboard-frontend/]
    Root --> Pkgs[/packages/]
    Root --> Serv[/services/]
    Root --> Tools[docker-compose.dev.yml<br/>Justfile<br/>.env.example<br/>pyproject.toml]

    Apps --> AF[Generated Clients<br/>Components<br/>Pages]
    Pkgs --> DB[database/]
    Pkgs --> SH[shared/]
    Serv --> CP[control_plane/]
    Serv --> IG[inference_gateway/]
```

---

## ğŸ› Troubleshooting

**`just migrate` fails with connection error**
â†’ Make sure Docker containers are running: `docker compose -f docker-compose.dev.yml up -d`

**Frontend shows blank page**
â†’ Run `just install-frontend` to regenerate API clients, then restart `just run-frontend`

**"Invalid or disabled API Key" in Playground**
â†’ Generate a new key from the Dashboard and paste the raw `sk-or-v1-...` value

**Gateway not reachable from frontend**
â†’ Both services must be running. Check `just run-gateway` is active on port 4000.

**Credits not updating**
â†’ The credit refresh happens after the stream completes. Wait for the full response.

---

*Built with intensity by Himmi. 2026.*
